# %% [markdown]
# # Notebook 06: Regresi√≥n Log√≠stica para Clasificaci√≥n
#
# **Secci√≥n 14**: Clasificaci√≥n Binaria
#
# **Objetivo**: Clasificar contratos seg√∫n riesgo de incumplimiento
#
# ## RETO PRINCIPAL: Crear tu propia variable objetivo
#
# **Problema**: El dataset no tiene una columna de "riesgo de incumplimiento".
# ¬°TENDR√ÅS QUE CREARLA!
#
# **Instrucciones**:
# Define un criterio para clasificar contratos como "alto riesgo" (1) o "bajo riesgo" (0)
#
# **Posibles criterios**:
# - Contratos con valor > percentil 90
# - Contratos con duraci√≥n > 365 d√≠as
# - Contratos de ciertos departamentos
# - Combinaci√≥n de m√∫ltiples factores
#
# **TU DECISI√ìN**: ¬øQu√© define un contrato de alto riesgo?

# %%
from pyspark.sql import SparkSession
from pyspark.ml.regression import LinearRegression
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.sql.functions import when, col
from pyspark.sql.functions import abs as spark_abs, col
from pyspark.ml.feature import StandardScaler, PCA, VectorAssembler
from pyspark.ml import Pipeline, PipelineModel
from delta import configure_spark_with_delta_pip
from pyspark.ml.feature import VectorAssembler
import numpy as np

# %%
# Configurar SparkSession
builder = (
    SparkSession.builder
    .appName("SECOP_EDA")
    .master("spark://spark-master:7077")
    .config("spark.executor.memory", "2g")
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension")
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")
)

spark = configure_spark_with_delta_pip(builder).getOrCreate()

print(f"Spark Version: {spark.version}")


# %%
# Cargar datos
df = spark.read.parquet("/opt/spark-data/processed/secop_features.parquet")
print(f"Registros: {df.count():,}")

# %% 
# RETO 1: Crear Variable Objetivo Binaria (Riesgo)


# 1. Calcular percentil 90 del valor del contrato
percentil_90 = df.approxQuantile(
    "valor_del_contrato_num",
    [0.9],
    0.01
)[0]

print(f"Percentil 90 del valor del contrato: ${percentil_90:,.2f}")

# 2. Definir variable objetivo binaria: riesgo
# Criterio:
# - Contratos cuyo valor est√° en el 10% superior (percentil 90)
# - Se consideran de ALTO RIESGO por:
#   ‚Ä¢ Mayor impacto financiero
#   ‚Ä¢ Mayor complejidad contractual
#   ‚Ä¢ Mayor probabilidad de retrasos o incumplimientos

df = df.withColumn(
    "riesgo",
    when(
        col("valor_del_contrato_num") >= percentil_90,
        1  # Alto riesgo
    ).otherwise(
        0  # Bajo riesgo
    )
)

# 3. Validaci√≥n r√°pida
print("\nDistribuci√≥n de la variable objetivo (riesgo):")
df.groupBy("riesgo").count().show()

# 4. Ver ejemplos
print("\nEjemplos de contratos clasificados como alto riesgo:")
df.filter(col("riesgo") == 1) \
  .select("valor_del_contrato_num", "riesgo") \
  .orderBy(col("valor_del_contrato_num").desc()) \
  .show(5, truncate=False)

# Criterio elegido:
#Valor del contrato ‚â• percentil 90

#Raz√≥n:
#Los contratos m√°s grandes concentran mayor riesgo financiero
#Tienen mayor complejidad operativa y administrativa
#En an√°lisis de contrataci√≥n p√∫blica, el tama√±o del contrato es un proxy razonable de riesgo


# %%
# RETO 2: Balance de Clases

from pyspark.sql.functions import col

print("\n=== DISTRIBUCI√ìN DE CLASES ===")

# Distribuci√≥n absoluta
class_distribution = df.groupBy("riesgo").count()
class_distribution.show()

# Totales
total = df.count()
clase_0 = df.filter(col("riesgo") == 0).count()
clase_1 = df.filter(col("riesgo") == 1).count()

# Porcentajes
pct_0 = clase_0 / total * 100
pct_1 = clase_1 / total * 100

print(f"Clase 0 (Bajo riesgo): {clase_0:,} registros ({pct_0:.1f}%)")
print(f"Clase 1 (Alto riesgo): {clase_1:,} registros ({pct_1:.1f}%)")

# Evaluaci√≥n autom√°tica de balance
if pct_1 < 10:
    print("\n‚ö†Ô∏è Dataset DESBALANCEADO")
elif pct_1 < 30:
    print("\n‚ö†Ô∏è Dataset PARCIALMENTE DESBALANCEADO")
else:
    print("\n‚úÖ Dataset razonablemente balanceado")

# -------------------------------
# DECISI√ìN T√âCNICA (COMENTARIOS)
# -------------------------------

# ¬øEst√° balanceado?
# NO, la clase de alto riesgo es claramente minoritaria.

# ¬øQu√© har√≠a?
# Opci√≥n elegida: C) Usar class_weight en el modelo

# Justificaci√≥n:
# - Evita duplicar registros artificialmente (oversampling)
# - No pierde informaci√≥n (a diferencia de undersampling)
# - Es la estrategia m√°s robusta para datasets medianos/grandes
# - Est√° soportada directamente por LogisticRegression en Spark
#
# Alternativas futuras:
# - Ajustar threshold de clasificaci√≥n
# - Probar oversampling solo para experimentaci√≥n

# %% [markdown]
# ## PASO 1: Preparar Datos

# %%
# Renombrar columnas para el modelo
df_binary = df.withColumnRenamed("riesgo", "label") \
               .withColumnRenamed("features_raw", "features")

# Filtrar nulos
df_binary = df_binary.filter(col("label").isNotNull() & col("features").isNotNull())

# Split train/test
train, test = df_binary.randomSplit([0.7, 0.3], seed=42)

print(f"Train: {train.count():,} registros")
print(f"Test:  {test.count():,} registros")

# %%
# RETO 3: Entender la Regresi√≥n Log√≠stica

#**Opciones**:
# - A) Predice probabilidades entre 0 y 1
# - B) Usa funci√≥n sigmoid
# - C) Es para clasificaci√≥n, no para valores continuos
# - D) Todas las anteriore
# Respuesta correcta:
# ‚úÖ D) Todas las anteriores

# Explicaci√≥n:
#
# La regresi√≥n log√≠stica se diferencia de la regresi√≥n lineal porque:
#
# - Predice probabilidades entre 0 y 1 (opci√≥n A),
#   que representan la probabilidad de pertenecer a la clase positiva.
#
# - Utiliza la funci√≥n sigmoide (opci√≥n B) para transformar
#   una combinaci√≥n lineal de las features en una probabilidad:
#
#       p = 1 / (1 + e^(-z))
#
# - Est√° dise√±ada para problemas de clasificaci√≥n (opci√≥n C),
#   no para predecir valores continuos como precios o montos.
#
# En resumen:
# La regresi√≥n log√≠stica modela la probabilidad de ocurrencia
# de un evento (ej. contrato de alto riesgo) y luego aplica
# un umbral para decidir la clase final (0 o 1).

# %%
# RETO 4: Configurar el Modelo de Regresi√≥n Log√≠stica

from pyspark.ml.classification import LogisticRegression

# Configuraci√≥n del modelo
lr_classifier = LogisticRegression(
    featuresCol="features",
    labelCol="label",
    maxIter=100,        # Iteraciones suficientes para convergencia
    regParam=0.1,       # Regularizaci√≥n L2 para prevenir overfitting
    elasticNetParam=0.0,# L2 (ridge)
    threshold=0.4       # Umbral ajustado por posible desbalance de clases
)

print("‚úì Clasificador configurado")
print(f"  ‚Ä¢ maxIter: {lr_classifier.getMaxIter()}")
print(f"  ‚Ä¢ regParam: {lr_classifier.getRegParam()}")
print(f"  ‚Ä¢ threshold: {lr_classifier.getThreshold()}")

# %%
# Respuesta conceptual:
#
# Si tienes 90% clase 0 y 10% clase 1:
# - Usar threshold=0.5 suele favorecer demasiado la clase mayoritaria
# - Es recomendable bajar el threshold (ej. 0.3‚Äì0.4)
# - Esto aumenta recall de la clase minoritaria (alto riesgo)
# - A costa de m√°s falsos positivos (trade-off aceptable en riesgo)

# %%
# Entrenar modelo
print("\nEntrenando clasificador log√≠stico...")
lr_model = lr_classifier.fit(train)
print("‚úì Modelo entrenado correctamente")

# %%
# PASO 2: Predicciones sobre el set de test

predictions = lr_model.transform(test)

print("\n=== PRIMERAS PREDICCIONES ===")
predictions.select(
    "label",
    "prediction",
    "probability"
).show(10, truncate=False)


# %%
# RETO 5: Interpretar Probabilidades (SOLUCI√ìN DEFINITIVA)

from pyspark.sql.functions import col
from pyspark.ml.functions import vector_to_array

# Explicaci√≥n conceptual:
#
# En Spark ML:
# probability = [p(clase 0), p(clase 1)]
#
# Ejemplo:
# probability = [0.8, 0.2]
# ‚Üí 80% probabilidad de clase 0 (bajo riesgo)
# ‚Üí 20% probabilidad de clase 1 (alto riesgo)
#
# ‚úÖ Respuesta correcta: A)

# %%
# Convertir VectorUDT ‚Üí Array
predictions = predictions.withColumn(
    "prob_array",
    vector_to_array(col("probability"))
)

# Extraer probabilidad de la clase positiva (√≠ndice 1)
predictions = predictions.withColumn(
    "prob_clase_1",
    col("prob_array")[1]
)

print("‚úì Probabilidad de clase 1 extra√≠da correctamente")

# %%
# Analizar casos "inseguros" (probabilidades cercanas al threshold)
print("\n=== CASOS CON PREDICCI√ìN INSEGURA (0.4 < P(clase 1) < 0.6) ===")

predicciones_dudosas = predictions.filter(
    (col("prob_clase_1") > 0.4) & (col("prob_clase_1") < 0.6)
)

predicciones_dudosas.select(
    "label",
    "prediction",
    "prob_clase_1"
).show(10, truncate=False)



# %%
# RETO 6: Evaluaci√≥n con M√∫ltiples M√©tricas

from pyspark.ml.evaluation import (
    BinaryClassificationEvaluator,
    MulticlassClassificationEvaluator
)

# =========================
# AUC - ROC
# =========================
evaluator_auc = BinaryClassificationEvaluator(
    labelCol="label",
    rawPredictionCol="rawPrediction",
    metricName="areaUnderROC"
)

auc = evaluator_auc.evaluate(predictions)

# =========================
# M√©tricas cl√°sicas de clasificaci√≥n
# =========================
evaluator_multi = MulticlassClassificationEvaluator(
    labelCol="label",
    predictionCol="prediction"
)

accuracy = evaluator_multi.evaluate(
    predictions,
    {evaluator_multi.metricName: "accuracy"}
)

precision = evaluator_multi.evaluate(
    predictions,
    {evaluator_multi.metricName: "weightedPrecision"}
)

recall = evaluator_multi.evaluate(
    predictions,
    {evaluator_multi.metricName: "weightedRecall"}
)

f1 = evaluator_multi.evaluate(
    predictions,
    {evaluator_multi.metricName: "f1"}
)

# =========================
# Resultados
# =========================
print("\n" + "="*60)
print("M√âTRICAS DE CLASIFICACI√ìN")
print("="*60)
print(f"AUC-ROC:   {auc:.4f}")
print(f"Accuracy:  {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1-Score:  {f1:.4f}")
print("="*60)

# =========================
# Interpretaci√≥n (comentarios)
# =========================
#
# ¬øEs bueno un AUC de 0.75?
#
# ‚úîÔ∏è S√≠, es un modelo razonablemente bueno.
#
# Interpretaci√≥n:
# - AUC = 0.5  ‚Üí modelo aleatorio
# - AUC ‚âà 0.7  ‚Üí modelo aceptable
# - AUC ‚âà 0.8  ‚Üí buen modelo
# - AUC ‚â• 0.9  ‚Üí excelente modelo
#
# Un AUC de 0.75 indica que el modelo distingue correctamente
# entre clases positivas y negativas el 75% del tiempo.
#
# En problemas de riesgo / fraude / incumplimiento:
# - AUC suele ser m√°s importante que accuracy
# - Recall suele priorizarse sobre precision
# - El threshold puede ajustarse seg√∫n el costo del error


# %%
# RETO 7: Matriz de Confusi√≥n
from pyspark.sql.functions import col

print("\n=== MATRIZ DE CONFUSI√ìN (label vs prediction) ===")

# Matriz de confusi√≥n agregada
confusion_matrix = (
    predictions
    .groupBy("label", "prediction")
    .count()
    .orderBy("label", "prediction")
)

confusion_matrix.show()

# =========================
# C√°lculo manual de m√©tricas
# =========================
TP = predictions.filter(
    (col("label") == 1) & (col("prediction") == 1)
).count()

TN = predictions.filter(
    (col("label") == 0) & (col("prediction") == 0)
).count()

FP = predictions.filter(
    (col("label") == 0) & (col("prediction") == 1)
).count()

FN = predictions.filter(
    (col("label") == 1) & (col("prediction") == 0)
).count()

print("\n=== DESGLOSE DE LA MATRIZ DE CONFUSI√ìN ===")
print(f"TP (True Positives):  {TP:,}")
print(f"TN (True Negatives):  {TN:,}")
print(f"FP (False Positives): {FP:,}")
print(f"FN (False Negatives): {FN:,}")

# =========================
# M√©tricas derivadas (√∫tiles para negocio)
# =========================
precision_manual = TP / (TP + FP) if (TP + FP) > 0 else 0
recall_manual = TP / (TP + FN) if (TP + FN) > 0 else 0

print("\n=== M√âTRICAS DERIVADAS ===")
print(f"Precision (manual): {precision_manual:.4f}")
print(f"Recall    (manual): {recall_manual:.4f}")

# =========================
# Interpretaci√≥n del problema (comentarios)
# =========================
#
# ¬øQu√© es peor en ESTE problema?
#
# FALSO POSITIVO (FP):
# - Predecir ALTO riesgo cuando en realidad es BAJO
# - Consecuencia:
#   ‚Ä¢ Posible rechazo innecesario
#   ‚Ä¢ Mayor control / burocracia
#   ‚Ä¢ Costo operativo
#
# FALSO NEGATIVO (FN):
# - Predecir BAJO riesgo cuando en realidad es ALTO
# - Consecuencia:
#   ‚Ä¢ Contrato riesgoso no detectado
#   ‚Ä¢ P√©rdidas econ√≥micas
#   ‚Ä¢ Riesgo legal / reputacional
#
# üëâ En problemas de riesgo / incumplimiento:
# ‚úîÔ∏è Normalmente el FALSO NEGATIVO es M√ÅS GRAVE
# ‚úîÔ∏è Por eso se prioriza RECALL sobre accuracy
# ‚úîÔ∏è Se puede bajar el threshold para detectar m√°s casos de riesgo

# %%
# RETO BONUS 1: Ajustar Threshold
# Objetivo: Evaluar el impacto del threshold en m√©tricas clave

from pyspark.ml.classification import LogisticRegression

thresholds = [0.3, 0.5, 0.7]

print("\n=== COMPARACI√ìN DE THRESHOLDS ===")

for t in thresholds:
    print(f"\n--- Threshold = {t} ---")

    # Configurar modelo con threshold espec√≠fico
    lr_temp = LogisticRegression(
        featuresCol="features",
        labelCol="label",
        maxIter=100,
        regParam=0.0,
        threshold=t
    )

    # Entrenar modelo
    model_temp = lr_temp.fit(train)

    # Predicciones
    preds_temp = model_temp.transform(test)

    # M√©tricas
    acc_temp = evaluator_multi.evaluate(
        preds_temp,
        {evaluator_multi.metricName: "accuracy"}
    )

    prec_temp = evaluator_multi.evaluate(
        preds_temp,
        {evaluator_multi.metricName: "weightedPrecision"}
    )

    rec_temp = evaluator_multi.evaluate(
        preds_temp,
        {evaluator_multi.metricName: "weightedRecall"}
    )

    f1_temp = evaluator_multi.evaluate(
        preds_temp,
        {evaluator_multi.metricName: "f1"}
    )

    auc_temp = evaluator_auc.evaluate(preds_temp)

    # Resultados
    print(f"Accuracy : {acc_temp:.4f}")
    print(f"Precision: {prec_temp:.4f}")
    print(f"Recall   : {rec_temp:.4f}")
    print(f"F1-Score : {f1_temp:.4f}")
    print(f"AUC-ROC  : {auc_temp:.4f}")

# =========================
# Reflexi√≥n (completar en markdown o comentario)
# =========================
#
# ¬øQu√© threshold elegir√≠as?
#
# - Threshold bajo (0.3):
#   ‚Ä¢ Mayor recall
#   ‚Ä¢ Detecta m√°s casos de alto riesgo
#   ‚Ä¢ M√°s falsos positivos
#
# - Threshold medio (0.5):
#   ‚Ä¢ Balance general
#   ‚Ä¢ Default en la mayor√≠a de modelos
#
# - Threshold alto (0.7):
#   ‚Ä¢ Mayor precisi√≥n
#   ‚Ä¢ Menos falsos positivos
#   ‚Ä¢ Riesgo de perder casos cr√≠ticos
#
# Elecci√≥n recomendada para riesgo:
# üëâ Threshold que MAXIMICE recall y controle FP aceptables


# %%
# RETO BONUS 2: Curva ROC
# Objetivo: Visualizar el trade-off entre TPR y FPR

import numpy as np
import matplotlib.pyplot as plt

# --------------------------------------------
# 1. Extraer probabilidades y labels a Pandas
# --------------------------------------------
prob_df = predictions.select("label", "probability").toPandas()

# Probabilidad de la clase positiva (1)
probs = np.array([p[1] for p in prob_df["probability"]])
labels = prob_df["label"].values

# --------------------------------------------
# 2. Calcular TPR y FPR para m√∫ltiples thresholds
# --------------------------------------------
thresholds_roc = np.linspace(0, 1, 100)
tpr_list = []
fpr_list = []

for t in thresholds_roc:
    y_pred = (probs >= t).astype(int)

    tp = np.sum((y_pred == 1) & (labels == 1))
    fp = np.sum((y_pred == 1) & (labels == 0))
    tn = np.sum((y_pred == 0) & (labels == 0))
    fn = np.sum((y_pred == 0) & (labels == 1))

    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0

    tpr_list.append(tpr)
    fpr_list.append(fpr)

# --------------------------------------------
# 3. Graficar Curva ROC
# --------------------------------------------
plt.figure(figsize=(8, 6))
plt.plot(fpr_list, tpr_list, label=f"AUC = {auc:.3f}")
plt.plot([0, 1], [0, 1], "r--", label="Random")
plt.xlabel("False Positive Rate (FPR)")
plt.ylabel("True Positive Rate (TPR)")
plt.title("Curva ROC")
plt.legend()
plt.grid(True)

# Guardar gr√°fico
roc_path = "/opt/spark-data/processed/roc_curve.png"
plt.savefig(roc_path)
plt.close()

print(f"‚úì Curva ROC guardada en: {roc_path}")


# %%
# Guardar modelo
model_path = "/opt/spark-data/processed/logistic_regression_model"
lr_model.write().overwrite().save(model_path)
print(f"\n‚úì Modelo guardado en: {model_path}")

# %%
print("\n" + "="*60)
print("RESUMEN CLASIFICACI√ìN")
print("="*60)
print(f"‚úì Criterio de riesgo definido")
print(f"‚úì Modelo entrenado")
print(f"‚úì AUC-ROC: {auc:.4f}")
print(f"‚úì F1-Score: {f1:.4f}")
print(f"‚úì Pr√≥ximo paso: Regularizaci√≥n (notebook 07)")
print("="*60)

# %%
spark.stop()
